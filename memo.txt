all_process.py
入力
・アーカイブ論文のpdfファイルまたはtextファイル
出力
・頻出単語をまとめたpptxファイル
必要環境
・MeCab(ライブラリ)
・pdfminer(ライブラリ)
・pptx(ライブラリ)
・title_master.py

all_process_filter.py
入力
・アーカイブ論文のpdfファイルまたはtextファイル
出力
・頻出単語から不要な単語を省いたものをまとめたpptxファイル
必要環境
・MeCab(ライブラリ)
・pdfminer(ライブラリ)
・pptx(ライブラリ)
・title_master.py
・eliminate_word_master.py
・eliminate_word_list.pickle

make_doc2vec.py
入力
・textファイル(単語ごとに半角スペースで区切り、論文ごとに改行で区切っています。改行区切りで文書ごとの特徴ベクトルを計算するようになります。)
出力
・学習済みのdoc2vecモデル
必要環境
・gensim(ライブラリ)

make_eliminate_word_list.py
入力
・アーカイブ論文のtextファイル
出力
・not_include_list.pickle(頻出単語として出現させていい単語)←他のソースでは使用していません
・eliminate_word_list.pickle(頻出単語として不要な単語のリスト)
必要操作
・実行するとコンソール上に単語が表示されるので、頻出単語として不要な場合は'z'を押してEnter、必要な場合はそれ以外を押してEnterを押します。半自動的に不要単語のリストを作成します。
必要環境
・eliminate_word_master.py
・MeCab(ライブラリ)

merge_for_doc2vec.py
入力
・アーカイブ論文のtextファイル
出力
・textファイル(単語ごとに半角スペースで区切り、論文ごとに改行で区切っています。)
必要環境
・MeCab(ライブラリ)

process_pdf.py
入力
・アーカイブ論文のpdfファイル
出力
・アーカイブ論文のtextファイル
必要環境
・pdfminer(ライブラリ)

save_frequency.py
入力
・アーカイブ論文のtextファイル
出力
・アーカイブ論文ごとの頻出単語のpickleファイル(archive_frequency_word_by10.pickleのようなファイル)
必要環境
・eliminate_word_master.py
・MeCab(ライブラリ)
・title_master.py

search_mean_word.py
入力
・学習済みのdoc2vecモデル
・クラスタリング結果のpickleファイル
出力
・word_title_set_list(変数名)(それぞれのクラスターに属する論文の平均の特徴量がどのような単語ベクトルと近いかをまとめています。単語リストとクラスターに属する論文タイトルリストがセットになっています。)
必要環境
・gensim(ライブラリ)
・title_master.py

similarity_detail.py
入力
・アーカイブ論文ごとの頻出単語のpickleファイル(archive_frequency_word_by10.pickleのようなファイル)
・学習済みのdoc2vecモデル
出力
・論文と類似論文、頻出単語をまとめたpptxファイル
必要環境
・gensim(ライブラリ)
・title_master.py
・pptx(ライブラリ)

similarity_matrix.py
入力
・学習済みのdoc2vecモデル
出力
・all_list.pickle(クラスタリング結果)
・gap_score.pickle(クラスタ数ごとのgap統計量)
必要環境
・gensim(ライブラリ)
その他
・論文同士の類似度行列はソースコード中のsimilarity_matrixという変数です。

title_master.py
ファイル名と論文タイトルをdict型で保持しています。
現状では手動で１つ１つ追加しています。